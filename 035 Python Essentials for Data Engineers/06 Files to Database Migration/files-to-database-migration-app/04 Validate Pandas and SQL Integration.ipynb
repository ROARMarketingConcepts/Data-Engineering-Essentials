{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function read_sql in module pandas.io.sql:\n",
      "\n",
      "read_sql(\n",
      "    sql,\n",
      "    con,\n",
      "    index_col: 'str | list[str] | None' = None,\n",
      "    coerce_float: 'bool' = True,\n",
      "    params=None,\n",
      "    parse_dates=None,\n",
      "    columns: 'list[str] | None' = None,\n",
      "    chunksize: 'int | None' = None,\n",
      "    dtype_backend: 'DtypeBackend | lib.NoDefault' = <no_default>,\n",
      "    dtype: 'DtypeArg | None' = None\n",
      ") -> 'DataFrame | Iterator[DataFrame]'\n",
      "    Read SQL query or database table into a DataFrame.\n",
      "\n",
      "    This function is a convenience wrapper around ``read_sql_table`` and\n",
      "    ``read_sql_query`` (for backward compatibility). It will delegate\n",
      "    to the specific function depending on the provided input. A SQL query\n",
      "    will be routed to ``read_sql_query``, while a database table name will\n",
      "    be routed to ``read_sql_table``. Note that the delegated function might\n",
      "    have more specific notes about their functionality not listed here.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    sql : str or SQLAlchemy Selectable (select or text object)\n",
      "        SQL query to be executed or a table name.\n",
      "    con : ADBC Connection, SQLAlchemy connectable, str, or sqlite3 connection\n",
      "        ADBC provides high performance I/O with native type support, where available.\n",
      "        Using SQLAlchemy makes it possible to use any DB supported by that\n",
      "        library. If a DBAPI2 object, only sqlite3 is supported. The user is responsible\n",
      "        for engine disposal and connection closure for the ADBC connection and\n",
      "        SQLAlchemy connectable; str connections are closed automatically. See\n",
      "        `here <https://docs.sqlalchemy.org/en/20/core/connections.html>`_.\n",
      "    index_col : str or list of str, optional, default: None\n",
      "        Column(s) to set as index(MultiIndex).\n",
      "    coerce_float : bool, default True\n",
      "        Attempts to convert values of non-string, non-numeric objects (like\n",
      "        decimal.Decimal) to floating point, useful for SQL result sets.\n",
      "    params : list, tuple or dict, optional, default: None\n",
      "        List of parameters to pass to execute method.  The syntax used\n",
      "        to pass parameters is database driver dependent. Check your\n",
      "        database driver documentation for which of the five syntax styles,\n",
      "        described in PEP 249's paramstyle, is supported.\n",
      "        Eg. for psycopg2, uses %(name)s so use params={'name' : 'value'}.\n",
      "    parse_dates : list or dict, default: None\n",
      "        - List of column names to parse as dates.\n",
      "        - Dict of ``{column_name: format string}`` where format string is\n",
      "          strftime compatible in case of parsing string times, or is one of\n",
      "          (D, s, ns, ms, us) in case of parsing integer timestamps.\n",
      "        - Dict of ``{column_name: arg dict}``, where the arg dict corresponds\n",
      "          to the keyword arguments of :func:`pandas.to_datetime`\n",
      "          Especially useful with databases without native Datetime support,\n",
      "          such as SQLite.\n",
      "    columns : list, default: None\n",
      "        List of column names to select from SQL table (only used when reading\n",
      "        a table).\n",
      "    chunksize : int, default None\n",
      "        If specified, return an iterator where `chunksize` is the\n",
      "        number of rows to include in each chunk.\n",
      "    dtype_backend : {'numpy_nullable', 'pyarrow'}, default 'numpy_nullable'\n",
      "        Back-end data type applied to the resultant :class:`DataFrame`\n",
      "        (still experimental). Behaviour is as follows:\n",
      "\n",
      "        * ``\"numpy_nullable\"``: returns nullable-dtype-backed :class:`DataFrame`\n",
      "          (default).\n",
      "        * ``\"pyarrow\"``: returns pyarrow-backed nullable :class:`ArrowDtype`\n",
      "          DataFrame.\n",
      "\n",
      "        .. versionadded:: 2.0\n",
      "    dtype : Type name or dict of columns\n",
      "        Data type for data or columns. E.g. np.float64 or\n",
      "        {'a': np.float64, 'b': np.int32, 'c': 'Int64'}.\n",
      "        The argument is ignored if a table is passed instead of a query.\n",
      "\n",
      "        .. versionadded:: 2.0.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    DataFrame or Iterator[DataFrame]\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    read_sql_table : Read SQL database table into a DataFrame.\n",
      "    read_sql_query : Read SQL query into a DataFrame.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    Read data from SQL via either a SQL query or a SQL tablename.\n",
      "    When using a SQLite database only SQL queries are accepted,\n",
      "    providing only the SQL tablename will result in an error.\n",
      "\n",
      "    >>> from sqlite3 import connect\n",
      "    >>> conn = connect(':memory:')\n",
      "    >>> df = pd.DataFrame(data=[[0, '10/11/12'], [1, '12/11/10']],\n",
      "    ...                   columns=['int_column', 'date_column'])\n",
      "    >>> df.to_sql(name='test_data', con=conn)\n",
      "    2\n",
      "\n",
      "    >>> pd.read_sql('SELECT int_column, date_column FROM test_data', conn)\n",
      "       int_column date_column\n",
      "    0           0    10/11/12\n",
      "    1           1    12/11/10\n",
      "\n",
      "    >>> pd.read_sql('test_data', 'postgres:///db_name')  # doctest:+SKIP\n",
      "\n",
      "    Apply date parsing to columns through the ``parse_dates`` argument\n",
      "    The ``parse_dates`` argument calls ``pd.to_datetime`` on the provided columns.\n",
      "    Custom argument values for applying ``pd.to_datetime`` on a column are specified\n",
      "    via a dictionary format:\n",
      "\n",
      "    >>> pd.read_sql('SELECT int_column, date_column FROM test_data',\n",
      "    ...             conn,\n",
      "    ...             parse_dates={\"date_column\": {\"format\": \"%d/%m/%y\"}})\n",
      "       int_column date_column\n",
      "    0           0  2012-11-10\n",
      "    1           1  2010-11-12\n",
      "\n",
      "    .. versionadded:: 2.2.0\n",
      "\n",
      "       pandas now supports reading via ADBC drivers\n",
      "\n",
      "    >>> from adbc_driver_postgresql import dbapi  # doctest:+SKIP\n",
      "    >>> with dbapi.connect('postgres:///db_name') as conn:  # doctest:+SKIP\n",
      "    ...     pd.read_sql('SELECT int_column FROM test_data', conn)\n",
      "       int_column\n",
      "    0           0\n",
      "    1           1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.read_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_uri = 'postgresql://itversity_retail_user:itversity@localhost:5432/itversity_retail_db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Using URI string without sqlalchemy installed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43morders\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mconn_uri\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Machine Learning and Data Analysis/Data-Engineering-Essentials/035 Python Essentials for Data Engineers/06 Files to Database Migration/files-to-database-migration-app/ftd_migration/lib/python3.13/site-packages/pandas/io/sql.py:704\u001b[0m, in \u001b[0;36mread_sql\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize, dtype_backend, dtype)\u001b[0m\n\u001b[1;32m    701\u001b[0m     dtype_backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m dtype_backend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default\n\u001b[0;32m--> 704\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mpandasSQL_builder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcon\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pandas_sql, SQLiteDatabase):\n\u001b[1;32m    706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m pandas_sql\u001b[38;5;241m.\u001b[39mread_query(\n\u001b[1;32m    707\u001b[0m             sql,\n\u001b[1;32m    708\u001b[0m             index_col\u001b[38;5;241m=\u001b[39mindex_col,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    714\u001b[0m             dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m    715\u001b[0m         )\n",
      "File \u001b[0;32m~/Desktop/Machine Learning and Data Analysis/Data-Engineering-Essentials/035 Python Essentials for Data Engineers/06 Files to Database Migration/files-to-database-migration-app/ftd_migration/lib/python3.13/site-packages/pandas/io/sql.py:903\u001b[0m, in \u001b[0;36mpandasSQL_builder\u001b[0;34m(con, schema, need_transaction)\u001b[0m\n\u001b[1;32m    900\u001b[0m sqlalchemy \u001b[38;5;241m=\u001b[39m import_optional_dependency(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqlalchemy\u001b[39m\u001b[38;5;124m\"\u001b[39m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(con, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m sqlalchemy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 903\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing URI string without sqlalchemy installed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    905\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sqlalchemy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(con, (\u001b[38;5;28mstr\u001b[39m, sqlalchemy\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39mConnectable)):\n\u001b[1;32m    906\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SQLDatabase(con, schema, need_transaction)\n",
      "\u001b[0;31mImportError\u001b[0m: Using URI string without sqlalchemy installed."
     ]
    }
   ],
   "source": [
    "pd.read_sql('orders',conn_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "    SELECT order_status, count(*) AS order_count\n",
    "    FROM orders\n",
    "    GROUP BY 1\n",
    "    ORDER BY 2 DESC\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Using URI string without sqlalchemy installed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconn_uri\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Machine Learning and Data Analysis/Data-Engineering-Essentials/035 Python Essentials for Data Engineers/06 Files to Database Migration/files-to-database-migration-app/ftd_migration/lib/python3.13/site-packages/pandas/io/sql.py:704\u001b[0m, in \u001b[0;36mread_sql\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize, dtype_backend, dtype)\u001b[0m\n\u001b[1;32m    701\u001b[0m     dtype_backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m dtype_backend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default\n\u001b[0;32m--> 704\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mpandasSQL_builder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcon\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pandas_sql, SQLiteDatabase):\n\u001b[1;32m    706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m pandas_sql\u001b[38;5;241m.\u001b[39mread_query(\n\u001b[1;32m    707\u001b[0m             sql,\n\u001b[1;32m    708\u001b[0m             index_col\u001b[38;5;241m=\u001b[39mindex_col,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    714\u001b[0m             dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m    715\u001b[0m         )\n",
      "File \u001b[0;32m~/Desktop/Machine Learning and Data Analysis/Data-Engineering-Essentials/035 Python Essentials for Data Engineers/06 Files to Database Migration/files-to-database-migration-app/ftd_migration/lib/python3.13/site-packages/pandas/io/sql.py:903\u001b[0m, in \u001b[0;36mpandasSQL_builder\u001b[0;34m(con, schema, need_transaction)\u001b[0m\n\u001b[1;32m    900\u001b[0m sqlalchemy \u001b[38;5;241m=\u001b[39m import_optional_dependency(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqlalchemy\u001b[39m\u001b[38;5;124m\"\u001b[39m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(con, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m sqlalchemy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 903\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing URI string without sqlalchemy installed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    905\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sqlalchemy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(con, (\u001b[38;5;28mstr\u001b[39m, sqlalchemy\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39mConnectable)):\n\u001b[1;32m    906\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SQLDatabase(con, schema, need_transaction)\n",
      "\u001b[0;31mImportError\u001b[0m: Using URI string without sqlalchemy installed."
     ]
    }
   ],
   "source": [
    "pd.read_sql(query, conn_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ftd_migration",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
